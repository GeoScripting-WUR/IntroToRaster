---
title: "Introduction to raster based analysis in R"
author: "Lo√Øc Dutrieux, Ben DeVries, Jan Verbesselt"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: "cosmo"
    toc: yes
    toc_depth: 4
    number_sections: true
cls: nature-no-superscript.csl
bibliography: refs.bib
---


# Today's learning objectives
At the end of the lecture, you should be able to:

* Read/write raster data 
* Perform basic raster file operations/conversions
* Perform simple raster calculations

# ToDo today

* Morning: Read the following tutorial
* 1.30 pm to 2.30 pm:
    * Feedback on yesterday's exercise,
    * clarifications about today's tutorial
    * Explanation of the exercise

* Rest of the afternoon: Do the exercise

# Assumed knowledge from previous lectures

* Understand system architecture (R, R packages, libraries, drivers, bindings)
* Good scripting habits


# Reminder on overall system architecture


<center><img src="figs/system_overview_2.png" alt="Drawing" style="width: 700px"/></center>



In a previous lectures you saw the overall system architecture (See figure above) and you saw how to read and write vector data from/to file into you R environment. These vector read/write operations were made possible thanks to the OGR library. The OGR library is interfaced with R thanks to the rgdal package/binding. By analogy, raster data can be read/written thanks to the GDAL library. The figure above provides an overview of the connections between these elements. GDAL stands for Geospatial Data Abstraction Library. You can check the project home page at [http://www.gdal.org/](http://www.gdal.org/) and you will be surprised to see that a lot of the software you have used in the past to read gridded geospatial data use GDAL. (i.e.: ArcGIS, QGIS, GRASS, etc). In this lesson, we will use GDAL indirectly via the raster package, which uses rgdal extensively. However, it is possible to call GDAL functionalities directly through the command line (a shell is usually provided with the GDAL binary distribution you installed on your system), which is equivalent to calling a `system()` command directly from within R. In addition, if you are familiar with R and its string handling utilities, it should facilitate the building of the expression that have to be passed to GDAL.


Perform system setup checks.
```{r}
# Example to perform system set-up checks
library(rgdal)
getGDALVersionInfo()
```

The previous function should return the version number of the current version of GDAL installed on your machine. 1.10.1 is the most recent stable release. In case the function above returns an error, or if you cannot install rgdal at all, you should verify that all required software and libraries are properly installed. Please refer to the [system setup page](http://geoscripting-wur.github.io/system_setup/).


# Overview of the raster package
The raster package is the reference R package for raster processing, Robert J. Hijmans is the original developer of the package.
The introduction of the raster package to R has been a revolution for geo processing and analysis using R. Among other things the raster package allows to:

* Read and write raster data of most commonly used format (thanks to extensive use of rgdal)
* Perform most raster operations (creation of raster objects, performing spatial/geometric operations (re-projections, resampling, etc), filtering and raster calculations)
* Work on large raster datasets thanks to its built-in block processing functionalities
* Perform fast operations thanks to optimized back-end C code
* Visualize and interact with the data
* etc...

Check the [home page](http://cran.r-project.org/web/packages/raster/) of the raster package, the package is extremely well documented, including vignettes and demos.

## Explore the raster objects
The raster package produces and uses R objects of three different classes. The **RasterLayer**, the **RasterStack** and the **RasterBrick**. A RasterLayer is the equivalent of a single layer raster, as an R workspace variable. The data themselves, depending on the size of the grid can be loaded in memory or on disk. The same stands for RasterBrick and RasterStack objects, which are the equivalent of multi-layer RasterLayer objects. RasterStack and RasterBrick are very similar, the difference being in the virtual characteristic of the RasterStack. While a RasterBrick has to refer to one multi-layer file or is in itself a multi-layer object with data loaded in memory, a RasterStack may ''virtually'' connect several raster objects written to different files or in memory. Processing will be more efficient for a RasterBrick than for a RasterStack, but RasterStack has the advantage of facilitating pixel based calculations on separate raster layers.

Let's take a look into the structure of these objects.
```{r}
library(raster)
# Generate a RasterLAyer object
r <- raster(ncol=40, nrow=20)
class(r) 
# Simply typing the object name displays its general properties / metadata
r
```
From the metadata displayed above, we can see that the RasterLayer object contains all the properties that geo-data should have; that is to say a projection, an extent and a pixel resolution.

RasterBrick and RasterStack objects can also fairly easily be generated directly into R, as shown in the example below. Being able to generate such objects without reading them from files is particularly important for the generation of ''reproducible examples'' which was covered in general terms in Lesson 3.

```{r}
# Using the previously generated RasterLAyer object
# Let's first put some values in the cells of the layer
r[] <- rnorm(n=ncell(r))
# Create a RasterStack objects with 3 layers
s <- stack(x=c(r, r*2, r))
# The exact same procedure works for creating a RasterBrick
b <- brick(x=c(r, r*2, r))
# Let's look at the properties of of one of these two objects
b
```
The RasterBrick metadata displayed above are mostly similar to what we saw earlier for the RasterLayer object, with the exception that these are multi-layer objects.

# Raster objects manipulations
## Reading and writing from/to file
The actual data used in geo processing projects often comes as geo-data, stored on files such as GeoTiff or other comonly used file formats. Reading data directly from these files into the R working environment (as objects belonging to one of the 3 raster objects classes), is made possible thanks to the raster package. The three main commands for reading raster objects from file are the `raster()`, `stack()`, and `brick()` functions, refering to RasterLayer, RasterStack and RasterBrick objects respectively.
Writing one of the three raster objects classes to file is achieved with the `writeRaster()` function.

To illustrate the reading and writing of raster files, we will use data subsets that we have prepared for the course and need to be downloaded from the repository. For that, make sure your working directory is set properly and run the following line; it will handle the download:

```{r, eval=FALSE}
# start by making sure that your working directory is properly set
# If not you can set it using setwd()
getwd()
download.file(url = 'https://github.com/GeoScripting-WUR/IntroToRaster/raw/gh-pages/data/LE71700552001036SGS00_SR_Gewata_INT1U.tif', destfile = 'LE71700552001036SGS00_SR_Gewata_INT1U.tif', method = 'auto')
# In case the download code doesn't work (mac, linux?), use method = 'wget'
```


Gewata is the name of the data set added, it is a multi Layer tiff object, its file name is LE71700552001036SGS00\_SR\_Gewata\_INT1U.tif, informing us that this is a subset from a scene acquired by the Landsat 7 sensor. Let's not worry about the region that the data cover for now, we will find a  nice way to discover that later on in that tutorial.
See the example below.

Now that we have downloaded the geoTiff file, it should be present in our working directory. We can investigate the content of the working directory (or any directory) using the `list.files()` function.

```{r, eval=FALSE}
# When passed without arguments, list.files() returns a list, listing the content of the working directory
list.files()
```

We can now load this object in R, since it is a multi-layer raster object, we need to use the `brick()` function to do that.

```{r, eval=FALSE}
gewata <- brick('LE71700552001036SGS00_SR_Gewata_INT1U.tif')
```
```{r, echo=FALSE}
gewata <- brick('data/LE71700552001036SGS00_SR_Gewata_INT1U.tif')
```
Let's take a look at the structure of this object.
```{r}
gewata
```
The metadata above informs us that the gewata object is a relatively small (593x653 pixels) RasterBrick with 6 layers.
Similarly, single layer objects can be read using the `raster()` function. Or if you try using the `raster()` function on a multi layer object, by default the first layer only will be read.
```{r, echo=FALSE}
gewataB1 <- raster('data/LE71700552001036SGS00_SR_Gewata_INT1U.tif')
gewataB1
```

```{r, eval=FALSE}
gewataB1 <- raster('LE71700552001036SGS00_SR_Gewata_INT1U.tif')
gewataB1
```

Note that in addition to supporting most commonly used geodata formats, the raster package has its own format. Saving a file using the `.grd` extension ('filename.grd') will automatically save the object to the raster package format. This format has great advantages when performing geo processing in R (one advantage for instance is that it conserves original filenames as layer names in multilayer objects), however, saving your final results in this file format might be risky as the GDAL drivers for that file format do not seem to exist yet.

## Geo processing, in memory Vs. on disk
When looking at the documentation of most functions of the raster package, you will notice that the list of arguments is almost always ended by `...`. These 'three dots' are called an ellipsis; it means that extra arguments can be passed to the function. Often these arguments are those that can be passed to the `writeRaster()` function; meaning that most geo-processing functions are able to write their output directly to file, on disk. This reduces the number of steps and is always a good consideration when working with big raster objects that tend to overload the memory if not written directly to file.

## Data type is (still) important
When writing files to disk using `writeRaster()` or the `filename =` argument in most raster processing function, you should set an appropriate data type. Use the `datatype =` argument, it will save some precious disk space, and increase read and writting speed.

See details in `?dataType`.

```{r, echo=FALSE, results='asis', eval=FALSE}
# Need to finish this table
library(knitr)
df <- data.frame(Fullname = c('Logical', 'Unsigned Integer 1', 'Signed Integer 1', 'Unsigned integer 2', 'Signed integer 2', 'Unsigned integer 4', 'Signed integer 4', 'Float 32', 'Float 64'),
                 'Raster Package Name' = c('LOG1S', 'INT1U', 'INT1S', 'INT2U', 'INT2S', 'INT4U', 'INT4S', 'FLT4S', 'FLT8S'),
                 'Minimum value' = c('FALSE (0)', '0', '-127', '0'))
kable(df)
```


 

## Croping a raster object
`crop()` is the raster package function that allows you to crop data to smaller spatial extents. A great advantage of the crop function is that it acceps almost all spatial object class of R as its ''extent'' input argument. But the ''extent'' argument also simply accepts objects of class ''extent''. One way of obtaining such an extent object interactively is by using the `drawExtent()` function. In the example below, we will manually draw a regular extent that we will use later to crop the gewata RasterBrick.

```{r, eval=FALSE}
# PLot the first layer of the RasterBrick
plot(gewata, 1)
e <- drawExtent(show=TRUE)
```

Now you have to define a rectangular bounding box that will define the spatial extent of the extent object. Click twice, for the two opposite corners of the rectangle.
Now we can crop the data following the boundaries of this extent.

```{r, eval=FALSE}
# Crop gewata using e
gewataSub <- crop(gewata, e)
# Now visualize the new cropped object
plot(gewataSub, 1)
```

You should see on the resulting plot that the orinal image has been cropped. 

## Creating layer stacks
To end this section on general files and raster objects manipulations, we will see how multi layer objects can be created from single layer objects. The object created as part of the example below is the same that we will later in the course to perform time series analysis on raster objects. It is composed of NDVI layers derived from Landat acquisitions at different dates. The objective is therefore to create a multi layer NDVI object, for which each layer corresponds to a different date.
But first we need to fetch the data, similarly to how we did it for the gewata brick, the data need to be downloaded from the repository where we put them.

```{r, eval=FALSE}
# Again, make sure that your working directory is properly set
getwd()
# Download the data
download.file(url='https://github.com/GeoScripting-WUR/IntroToRaster/raw/gh-pages/data/tura.zip', destfile='tura.zip', method='auto')
unzip(zipfile='tura.zip')
# Retrieve the content of the tura sub-directory
list <- list.files(path='tura/', full.names=TRUE)
```

The object `list` contains the file names of all the single layers we have to stack. Let's open the first one to visualize it.

```{r, eval=FALSE}
plot(raster(list[1]))
```

We see a NDVI layer, with the cloud masked out. Let's now create the stack, the function for doing that is called `stack()`. Looking at the help page of the function , you can see that it can accep a list of file names as argument, which is exactly what the object ''list'' is. So we can very simply create the layer stack by running the function.

```{r, eval=FALSE}
turaStack <- stack(list)
turaStack
```

Now that we have our 166 layers RasterStack in memory, let's write it to disk using the `writeRaster()` function. Note that we decide here to save it as .grd file (the native format of the raster package); the reason for that is that this file format conserves original file names (in which information on dates is written) in the individual band names. The data range is comprised between -10000 and +10000, therefore such a file can be stored as signed double integer (INT2S).

```{r, eval=FALSE}
# Write this file at the root of the working directory
writeRaster(x=turaStack, filename='turaStack.grd', datatype='INT2S')
```

Now this object is stored on your computer, ready to be archived for later use.

# Simple raster arithmetic
## Adding, substracting, multiplying and dividing RasterLayers
Performing simple raster operations with raster objects is fairly easy. For instance, if you want to substract two RasterLayers of same extent, r1 and r2; simply doing `r1 - r2` will give the expected output, which is, every pixel value of r2 will be substracted to the matching pixel value of r1. These types of pixel based operations almost always require a set of conditions to be met in order to be executed; the two RasterLayers need to be identical in term of extent, resolution , projection, etc.

## Subsetting layers from from RasterStack and RasterBrick
Different spectral bands of a same satellite image scene are often stored in multi layers objects. This means that you will very likely import them in you R working environment as RasterBrick or RasterStack objects. As a consequence, to perform calculations between these bands, you will have to write an expression refering to individual layers of the object. Referring to individual layers in a RasterBrick or RasterStack object is done by using double square brackets `[[]]`.
Let's look for instance at how the famous NDVI index would have to be calculated from the gewata RasterBrick object read earlier, and that contains the spectral bands of Landsat 7 sensor. And in case you have forgotten, the ndvi formula is as follows.

$$
 NDVI=\frac{NIR-R}{NIR+R} 
$$

with NIR and R being band 4 and 3 of Landsat respectively.

```{r}
ndvi <- (gewata[[4]] - gewata[[3]]) / (gewata[[4]] + gewata[[3]])
```

The `plot()` function automatically recognises the objects of raster classes and returns an appropriate spatial plot.

```{r, ndvi, echo=TRUE, fig=TRUE, fig.align='center'}
plot(ndvi)
```


The resulting NDVI can be viewed in the above figure. As expected the NDVI ranges from about 0.2, which corresponds to nearly bare soils, to 0.9 which means that there is some dense vegetation in the area.

Although this is a quick way to perform the calculation, directly adding, substracting, multiplying, etc, the layers of big raster objects is not recommended. When working with big objects, it is advisable to use the `calc()` function to perform these types of calculaions. The reason is that R needs to load all the data first into its internal memory beform performing the calculation and then runs everything in one block. It is really easy to ''flood'' the RAM when doing that. A big advantage of the `calc()` function is that it has a built-in block processing option for any vectorized function, allowing such calculations to be fully ''RAM friendly''. The example below illustrates how to calculate NDVI from the same date set using the `calc()` function.

```{r}
# Define the function to calculate NDVI from 
ndvCalc <- function(x) {
    ndvi <- (x[[4]] - x[[3]]) / (x[[4]] + x[[3]])
    return(ndvi)
}
ndvi2 <- calc(x=gewata, fun=ndvCalc)

```

Note that `overlay()` can also be used in that case to obtain the same result, with the same level of RAM friendlyness. The advantage of overlay being that the number of input RasterLayers is less limiting. As a consequence specifying the layers does not happen in the function call but in the `overlay()` call instead. 

```{r}
ndvOver <- function(x, y) {
    ndvi <- (y - x) / (x + y)
    return(ndvi)
}
ndvi3 <- overlay(x=gewata[[3]], y=gewata[[4]], fun=ndvOver)
```

We can verify that the three layers ndvi, ndvi2 and ndvi3 are actually identical using the `all.equal()` function from the raster package. 

```{r}
all.equal(ndvi, ndvi2)
all.equal(ndvi, ndvi3)
```

In the simple case of calculating NDVI, we were easily able to produce the same result with `calc()` and `overlay()`, however, it is often the case that one function is preferable to the other. As a general rule, a calculation that needs to refer to multiple individual layers separately will be easier to set up in `overlay()` than in `calc()`.

## Re-projections
By the way, we still don't know where this area is. In order to investigate that, we are going to try projecting it in Google Earth. As you know Google Earth is all in Lat/Long, so we have to get our data re-projected to lat/long first. The `projectRaster()` function allows re-projection of raster objects to any projection one can think of. As the function uses the [PROJ.4](https://trac.osgeo.org/proj/) library (PROJ.4 is the reference library (external to R) that handles cartographic projections and performs projections transformations; the rgdal package is the interface between that library and R) to perform that operation, the `crs=` argument should receive a ''proj4'' expression. ''proj4'' expressions are strings that provide the projection parameters of cartographic projections. A central place to search for projections is the spatial reference website ([http://spatialreference.org/](http://spatialreference.org/)), from this database you will be able to query almost any reference and retrieve it in any format, including its Proj4 expression.

```{r}
# One single line is sufficient to project any raster to any projection
ndviLL <- projectRaster(ndvi, crs='+proj=longlat')
```


Note that if re-projecting and mosaicking is really a large part of your project, you may want to consider using directly the `gdalwarp` command line utility ([gdalwarp](http://www.gdal.org/gdalwarp.html)). The `gdalUtils` R package provides utilities to run GDAL commands from R, including gdalwarp, for reprojection, resampling and mosaicking.

Now that we have our ndvi layer in lat/long, let's write it to a kml file, which is one of the two Google Earth formats.

```{r, eval = FALSE}
# Since this function will write a file to your working directory
# you want to make sure that it is set where you want the file to be written
# It can be changed using setwd()
getwd()
# Note that we are using the filename argument, contained in the elypsis (...) of 
# the function, since we want to write the output directly to file.
KML(x=ndviLL, filename='gewataNDVI.kml')
```

Note that you need to have Google Earth installed on your system in order to perform the following step.
Now let's find that file that we have just written and double click it, and watch how Google Earth brings us all the way to ... Ethiopia. More information will come later in the course about that specific area.

We are done with this data set for this lesson. So let's explore another data set, from the Landsat sensors. This dataset will allow us to find other interesting raster operations to perform.  

## More raster arythmetics, perform simple value replacements

Since 2014, the USGS has started releasing Landsat data processed to surface reflectance. This mean that they are taking care of important steps such as atmospheric correction and conversion from sensor radiance to reflectance. Additionaly, they provide with this product a cloud mask, which is an extra raster layer, at the same resolution than the surface reflectance bands, that contains information about the presence or absence of cloud as well as shadowing effects from the clouds. The cloud mask of Landsat surface reflectance product is named cfmask, after the name of the algorithm used to detect the clouds. For more information about cloud detection, see the [algorithm page](https://code.google.com/p/fmask/), and the publication by @zhu2012object.
In the following section we will use that cfmask layer to mask out remaining clouds in a Landsat scene.


### About the area
The area selected for this exercise covers most of the South Pacific island of Tahiti, French Polynesia. It is a mountaneous, volcanic island, and according to Wikipedia about 180,000 people live on the island. For convenience, the Landsat scene was subsetted to cover only the area of interest and is stored online.

```{r, eval=FALSE}
# Download the data
download.file(url='https://github.com/GeoScripting-WUR/IntroToRaster/raw/gh-pages/data/LE70530722000126_sub.gri', destfile='LE70530722000126_sub.gri', method='auto')
download.file(url='https://github.com/GeoScripting-WUR/IntroToRaster/raw/gh-pages/data/LE70530722000126_sub.grd', destfile='LE70530722000126_sub.grd', method='auto')

# Load the data as a rasterBrick object and investigate its content
tahiti <- brick('LE70530722000126_sub.grd')
tahiti

# Display names of each individual layers
names(tahiti)

# Visualize the data
plotRGB(tahiti, 3,4,5)
```

<!--
In linux the argument 'auto' does not work for https download. Can be replaced by 'wget'. What about macOS
-->

```{r, echo=FALSE, fig.align='center'}
tahiti <- brick('data/LE70530722000126_sub.grd')
plotRGB(tahiti, 3,4,5)
```

We can also visualize the cloud mask layer (layer 7).
```{r, fig.align='center'}
plot(tahiti, 7)
```

According to the [algorithm description](https://code.google.com/p/fmask/), water is coded as 1, cloud as 4 and cloud shadow as 2.

Does the cloud mask fit with the visual interpretation of the RGB image we plotted before?

We can also plot the two on top of each others, but before that we need to assign no values to the 'clear land pixels' so that they appear transparent on the overlay plot.

```{r, fig.align='center'}
# Extract cloud layer from the brick
cloud <- tahiti[[7]]

# Replace 'clear Land by NA'
cloud[cloud == 0] <- NA

# Plot the stack and the cloud mask on top of each others
plotRGB(tahiti, 3,4,5)
plot(cloud, add = TRUE, legend = FALSE)
```

Applying a cloud mask to a dataset simply consists in performing value replacement. In this case, a condition on the 7th layer of the stack (the fmask layer) will determine whether values in the other layers are kept, or replaced by NA, which is equivalent to masking them.
It is more convenient to work on the cloud mask as a separate rasterLayer, we will therefore split the rasterBrick using the `dropLayer()` function.

```{r}
# Extract cloud Mask rasterLayer
fmask <- tahiti[[7]]
# Remove fmask layer from the Landsat stack
tahiti6 <- dropLayer(tahiti, 7)
```

We will first do the masking using simple vector arithmetic, as if `tahiti6` and `fmask` were simple vectors. We want to keep any value with a 'clean land pixel flag' in the cloud mask; or rather, since we are assigning NAs, we want to discard any value of the stack which has a corresponding cloud mask pixel diffent from 0. This can be done in one line of code.

```{r}
# Perform value replacement
tahiti6[fmask != 0] <- NA
```

However, this is possible here because both objects are relatively small and the values can all be loaded in the computer memory without any risk of overloading it. When working with very large raster objects, you will very likely run into problems if you do that. It is then preferable, as presented earlier in this tutorial to use `calc()` or `overlay()`. `overlay()` in this case is the appropriate function, since we are working with two distinct raster objects.

```{r}
# First define a value replacement function
cloud2NA <- function(x, y){
    x[y != 0] <- NA
    return(x)
}
```

The value replacement function takes two arguments, x and y. Similarly to what we did earlier, x corresponds to the cloud mask, and y to the rasterBrick.

```{r, fig.align='center'}
# Let's create a new 6 layers object since tahiti6 has been masked already
tahiti6_2 <- dropLayer(tahiti, 7)

# Apply the function on the two raster objects using overlay
tahitiCloudFree <- overlay(x = tahiti6_2, y = fmask, fun = cloud2NA)

# Visualize the output
plotRGB(tahitiCloudFree, 3,4,5)
```


There are holes in the image, but at least the clouds are gone. We could use another image from another date, to create a composited image, but that is little bit too much for today.

# Summary
Today you got a general introduction to the raster package, its basic functions, its object classes and methods. The can be categorized as follows:

## Raster classes

* `RasterLayer`: Single layer object
* `RasterStack` and `RasterBrick`: Multi-layer raster objects

## Functions

### Read data

* `raster()`: Read a single layer raster object written on disk, or read the first layer of a multi-layer object.
* `brick()`: Read a multi-layer raster object written on disk.

### Write data

* `writeRaster()`: Write a `RasterLayer`, `RasterBrick` or `RasterStack` to disk.
* `filename =` argument: Available for most functions of the raster package that produce raster objects, write directly the output of the function to disk.

### Reformat data

* `crop()`: modify the extent of a raster object based on another spatial object or an extent object.
* `projectRaster()`: Re-project (and resample) a raster object to a desired coordinate reference system.
* `stack()`: Assemble RasterLayers in a multilayer object.
* `dropLayer()`: Remove a layer from a multi-layer object (RasterStack or RasterBrick).

### Simple visualization

* `plot()`: Plot a raster object, use `add = TRUE` to overlay several objects.
* `plotRGB()`: Plot a RGB color composite

### Raster calculations

* First of all, raster objects work just like vectors of numerics (`c(1,2,3)`). They can be subsetted, added, substracted, etc
* `calc()`: Apply a function to every pixel independently of a single raster object (Single or multi-layer). RAM friendly and can write output directly to disk using the `filename =` argument.
* `overlay()`: Apply a function that takes values from multiple raster objects. (similar to `calc()` but for multiple objects).


# Hdf files
*The information [here](hdf.html), about handling HDF4 format files with R is additional to the lesson content, however, it will be usefull for you in the future; particularly if you plan to work with MODIS data*



# Packages you should know about
The [gdalUtils](http://cran.r-project.org/web/packages/gdalUtils/index.html) package provides interesting wrappers facilitating the use of gdal functions from within R.


# Exercise: *Design a pre-processing chain to assess change in NDVI over time*

I would like to know if Wageningen and its surrounding has changed with respect to its spring NDVI over the past 15 years. For that I would need to do a bi-temporal comparison of two NDVI images, acquired in spring. Simply substracting the images should work, but unfortunately these haven't been pre-processed yet. I managed to download two Landsat raw surface reflectance products covering the area. They were acquired around the same period of the year at about 30 years interval, but I don't know how to compare them. Can you please help me?

## More details

* Data can be found [here](https://www.dropbox.com/s/i1ylsft80ox6a32/LC81970242014109-SC20141230042441.tar.gz?dl=0), and [here](https://www.dropbox.com/s/akb9oyye3ee92h3/LT51980241990098-SC20150107121947.tar.gz?dl=0).
* Can you tell when the scene were acquired ? (hint: look in file names)
* Product details are [here](http://landsat.usgs.gov/documents/provisional_l8sr_product_guide.pdf) (Landsat 8) and [here](http://landsat.usgs.gov/documents/cdr_sr_product_guide.pdf) (Landsat 5)
* Cloud mask from the fmask algorithm is contained in both archives
* The two scenes have different extents


Note: Landsat 8 does not use the same band numbers as its predecessors. So that RED and NIR correspond to band3 and band4 respectively for ETM+ and TM (Landsat 7 and 5 respectively), while for OLI (Landsat 8), RED is band4 and NIR band5.

## Hints

* `list.files()` with `pattern =` argument. For example, `list.files('data/', pattern = glob2rx('*.tif'), full.names = TRUE)` will return only the files that have the `.tif` extension.
* You should always use `full.names = TRUE` in `list.files()` to be able to use the output.
* `?intersect`
* `untar()` to programmatically extract the files from the archive.

## How to submit
Create a well structured reproducible R project showing in the `main.R`.

* The workflow to pre-process the data
* Some visualization of the intermediary outputs
* How to produce and visualize the final output

# References


<!--
# Exercise: write a compositing function

## Context
We would really like to have a cloud free image of Tahiti, unfortunately as we saw earlier the first image we downloaded and filtered for cloud contamination discarded a lot of pixels. Luckily there is another image available for the same area, acquired around the same time as the first one. This second image is also partially contaminated by clouds, but they appear to be at different locations. Can you create a composited image that uses the two images of tahiti?

## Expected output
Using the two tahiti images, write a mean value compositing function. The function should accepts 2 `RasterBrick` or `RasterStack` objects - containing 7 bands and band 7 being the 'fmask layer - and return a 6 layers `RasterStack` or `RasterBrick` object. In case of cloud occurence at both dates, pixel value should be NA, if both dates are cloud free, the mean value will be returned.

## Hints
There are many ways to create such function, one fast way would be to:

* Remove band 7 from both RasterStack objects
* Replace cloud contaminated pixels by NAs
* Write a micro function that performs the averaging, as described in the exercise definition (take a look at the `na.rm=` argument in the `mean()` function).
* Apply the function to the RasterStack objects using `calc()` or `overlay()`. Depending on how you wrote the it, it is possible that `overlay()` complains about the function not being vectorized. One quick way to vectorize a function that has multiple input arguments is by using `mapply()`. See the example below.
```{r, eval=FALSE}
# Considering a non vectorised function, with 2 input arguments (a, b)
# called RandomFunction()
# The vectorized version (VRandomFunction()) can be created as follows
VRandomFunction <- function(a, b) {
    out <- mapply(FUN=RandomFunction, a, b)
    return(out)
}
```

* Wrap all that into a clean, nicely written and documented function.

-->


